[{"title":"mongodb aggregate","path":"2017/03/29/mongodb-aggregate/","text":"背景 需求：删除mongodb中重复的“阶段数据”,阶段表中大概有近百万数据。 方案：按照 “orderid、stepname 分组”，并统计分组中条目数量，筛选出数量大于1的结果，并且按照“createdate”排序。 数据表1CMD:db.col.step.find() 1234567891011121314151617181920&#123;&quot;_id&quot; : ObjectId(&quot;58cfaec9f2aeba9d23c2796f&quot;),&quot;Step&quot; : &quot;Purchasing&quot;,&quot;OrderId&quot; : NumberInt(&quot;11853559&quot;),&quot;PurchaseType&quot; : &quot;Agent&quot;,&quot;ShipmentTypeId&quot; : NumberInt(&quot;7&quot;),&quot;CustomerId&quot; : NumberInt(&quot;646340&quot;),&quot;CatalogCode&quot; : &quot;SG&quot;,&quot;OriginCode&quot; : &quot;CN&quot;,&quot;CreateDate&quot; : NumberLong(&quot;1490005705&quot;),&quot;UpdateDate&quot; : NumberLong(&quot;1490005705&quot;),&quot;IsStepTimeout&quot; : true,&quot;StepStartAt&quot; : NumberLong(&quot;1489487036&quot;),&quot;StepEndAt&quot; : NumberLong(&quot;1489716666&quot;),&quot;StepDuration&quot; : NumberLong(&quot;229630&quot;),&quot;Log&quot; : [ &quot;2017-03-14 18:23:56\\tOrder Processing&quot;, &quot;2017-03-17 10:11:06\\tOrder Placed&quot;],&quot;Compensation&quot; : 2&#125;,… 聚合脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849var curdb=db.getSiblingDB(&quot;T24HRCompensation&quot;);var rs=curdb.model.T24HRStepStatistics.aggregate([&#123; $sort: &#123; // 先排序，影响聚合结果中data数组的顺序 CreateDate: 1 &#125;&#125;, &#123; // 分组 $group: &#123; // 以 orderid 和stepname 两个维度分组，相当于两个字段联合唯一 _id: &#123; &quot;orderId&quot;: &quot;$OrderId&quot;, &quot;stepName&quot;: &quot;$Step&quot; &#125;, // 统计分组中条目数 count: &#123; $sum: 1 &#125;, // 将 $$ROOT(表示源数据，这里是每一分组中的数据) data: &#123; // 将源数据放到data数组中 $push: &apos;$$ROOT&apos; &#125; &#125;&#125;, &#123; // 最终筛选条件，影响哪些分组数据显示出来 $match: &#123; count: &#123; $gt: 1 &#125; &#125;&#125;], &#123; // mongodb aggregate 会限制文档不大于16MB // 这个选项可以将聚合数据写到 dbpath下的tmp文件中，当做临时缓存，而不是都放在内存中。 allowDiskUse: true &#125;);// cursor 遍历rs.forEach(function(myDoc) &#123; var n = myDoc.count; var id = myDoc._id; var data = myDoc.data; print(n,id.stepName) for (var i = 1;i &lt; n;i++)&#123; // 删除除了最早创建的数据以外的所有重复数据 curdb.model.T24HRStepStatistics.remove(&#123;_id:data[i]._id&#125;); &#125;;&#125;); 结果&amp;总结第一次运行，提示 : 123456789Error: Printing Stack Trace at printStackTrace (src/mongo/shell/utils.js:37:15) at DBCollection.aggregate (src/mongo/shell/collection.js:897:9) at (shell):1:30Wed Mar 29 14:51:16.315 aggregate failed: &#123; &quot;errmsg&quot; : &quot;exception: Sort exceeded memory limit of 104857600 bytes, but did not opt in to external sorting. Aborting operation. Pass allowDiskUse:true to opt in.&quot;, &quot;code&quot; : 16819, &quot;ok&quot; : 0&#125; at src/mongo/shell/collection.js:898 由于没有对 sort字段建立索引，建立后，重新运行： 123456789Error: Printing Stack Trace at printStackTrace (src/mongo/shell/utils.js:37:15) at DBCollection.aggregate (src/mongo/shell/collection.js:897:9) at (shell):1:30Wed Mar 29 15:19:37.383 aggregate failed: &#123; &quot;errmsg&quot; : &quot;exception: Exceeded memory limit for $group, but didn&apos;t allow external sort. Pass allowDiskUse:true to opt in.&quot;, &quot;code&quot; : 16945, &quot;ok&quot; : 0&#125; at src/mongo/shell/collection.js:898 可以看到 sort 的内存限制问题没有再出现，但是分组内存限制问题出现了，这时候 添加 allowDiskUse:true 选项后得到解决。 另： sort 不支持外部sort ，要到db本机去执行上述命令。 引用 mongo docs mongodb 使用小结 mongodb 聚合报错 mongodb 聚合","tags":[{"name":"数据库","slug":"数据库","permalink":"https://yeqianming.github.io/tags/数据库/"},{"name":"mongo","slug":"mongo","permalink":"https://yeqianming.github.io/tags/mongo/"},{"name":"工程实践","slug":"工程实践","permalink":"https://yeqianming.github.io/tags/工程实践/"}]},{"title":"golang internal package","path":"2017/03/07/golang-internal-package/","text":"概述go internal 包，一种安全隔离机制，可以保证内部包只被特定的引用，而不是任何其他包都可以引用。 规则 ： 如果导入代码位于“internal”目录的父目录为根的树外部，则无法导入包含internal的路径的包。 例子 /a/b/c/internal/d/e 中代码只能被以 /a/b/c 为根目录的树中代码导入。 引用 Go 1.4 internal packages","tags":[{"name":"go","slug":"go","permalink":"https://yeqianming.github.io/tags/go/"}]},{"title":"vim 查找","path":"2017/03/03/vim-查找/","text":"普通查找 cmd: / 向后查找 cmd: ? 向前查找 全词匹配 cmd: word\\&gt; 后缀匹配 cmd: \\&lt;word 前缀匹配 cmd: \\&lt; word \\&gt; 全词匹配 大小写 cmd: :set ignorecase // 忽略大小写 cmd: :set noignorecase // 恢复大小写敏感","tags":[{"name":"vim","slug":"vim","permalink":"https://yeqianming.github.io/tags/vim/"}]},{"title":"shell shift","path":"2017/02/28/shell-shift/","text":"概述​ shift 命令用于对参数进行左移，可以在循环遍历控制参数数的递减，也可以去掉左边不需要的参数。shift 命令每执行一次，参数数减一，参数位置依次左移一位，比如之前的 $1 被清除，$2变成$1。同理 shift n 表示前n位参数被清除。 例子123456789101112__contains_word()&#123; echo $@ local w word=$0; shift echo $@ for w in &quot;$@&quot;; do echo $w [[ $w = &quot;$word&quot; ]] &amp;&amp; return done return 1&#125;__contains_word aaa aaaf ddd xxx eee 输出： aaa aaaf ddd xxx eeeaaaf ddd xxx eeeaaafdddxxxeee","tags":[{"name":"shell","slug":"shell","permalink":"https://yeqianming.github.io/tags/shell/"}]},{"title":"golang cookieJar","path":"2017/02/15/golang-cookieJar/","text":"使用情景当完成登录后，会从服务端response获取到cookie，其中包含了鉴权准入等信息。在后续的请求的cookie加入该信息后，便可以直接访问需要登录过的权限的其他服务api。 代码可以使用 CookieJar: 12345678910111213import &quot;net/http/cookiejar&quot;func main() &#123; var client http.Client jar, err := cookiejar.New(nil) if err != nil &#123; panic(err) &#125; client.Jar = jar client.Post(...) // 在这里登陆 client.Get() // 后续请求client会自动将cookie加入&#125;","tags":[{"name":"go","slug":"go","permalink":"https://yeqianming.github.io/tags/go/"},{"name":"web","slug":"web","permalink":"https://yeqianming.github.io/tags/web/"}]},{"title":"赋值的原子性讨论","path":"2017/02/15/赋值的原子性讨论/","text":"转载自csdn博客 C语言赋值语句是不是原子操作？ 经常看到有同学讨论，C语言的赋值语句是不是原子操作？C语言的++语句是不是原子操作？ webopedia: Atomic implies indivisibility and irreducibility, so an atomic operation must be performed entirely or not performed at all.An operation during which a processor can simultaneously read a location and write it in the same bus operation. This prevents any other processor or I/O device from writing or reading memory until the operation is complete. osdev:An atomic operation is an operation that will always be executed without any other process being able to read or change state that is read or changed during the operation. It is effectively executed as a single step, and is an important quality in a number of algorithms that deal with multiple indepent processes, both in synchronization and algorithms that update shared data without requiring synchronization. 相关概念时钟周期、总线周期和指令周期 1.时钟周期：微处理器执行指令的最小时间单位，又称T状态。它通常与微机的主频有关。 2.总线周期：CPU对存储器或I/O端口完成一次读/写操作所需的时间。如8086微处理器的基本总线周期由四个时钟周期T1～T4组成，80486微处理器的基本总线周期由T1和T2两个时钟周期组成。当外设速度较慢时，可插入等待周期Tw。 3.指令周期：CPU执行一条指令所需要的时间。指令周期由若干个总线周期组成，不同指令执行的时间不同。同一功能的指令，在寻址方式不同时，所需要的时间也不同。 总线操作周期微机系统各部件之间的信息交换是通过总线操作周期完成的，一个总线周期通常分为以下四个阶段。 1.总线请求和仲裁阶段：当有多个模块提出总线请求时，必须由仲裁机构仲裁，确定将总线的使用权分配给哪个模块。 2.寻址阶段：取得总线使用权的模块，经总线发出本次要访问的存储器或I/O端口的地址和有关命令。 3.传送数据阶段：主模块（指取得总线控制权的模块）与其他模块之间进行数据的传送。 4.结束阶段：主模块将有关信息从总线上撤除，主模块交出对总线的控制权。 结论CPU最小的执行单元是指令，一个指令周期可能包括多个总线周期。我们可以得到： 1. 在单处理器下，一个操作只包括一个cpu指令可以保证是原子操作。如果一个操作包含多个cpu指令不是原子操作。 2. 在多处理器下，由于一个cpu指令周期可能包含多个总线周期，就有可能出现其他处理器在一个指令执行期间访问了其相关的状态。因此，多处理器下，指令执行期间还必须锁总线，才能保证CPU指令的原子性 我们看下C语言的赋值和++操作代码main.c： 123456789101112131415#include &lt;stdio.h&gt; void fun1() &#123; volatile int m; volatile int n; m = 99; n = m; &#125; void fun2() &#123; volatile int n = 10; n++; &#125; int main(int argc, char** argv) &#123; fun(); return 0; &#125; 汇编：gcc -S main.c查看fun1相关的指令： 123456pushq %rbp movq %rsp, %rbp movl $99, -4(%rbp) movl -4(%rbp), %eax movl %eax, -8(%rbp) leave fun2相关指令： 1234567pushq %rbp movq %rsp, %rbp movl $10, -4(%rbp) leaq -4(%rbp), %rax incl (%rax) movl %eax, -4(%rbp) leave 可以看到，n = m为两条指令： movl -4(%rbp), %eax movl %eax, -8(%rbp) n++三条指令： leaq -4(%rbp), %rax incl (%rax) movl %eax, -4(%rbp)都是多条指令，所以，不是原子操作。 总结：原子操作和硬件实现、编译器实现都紧密相关，因此，单纯的在高级语言的层次讨论原子操作，没有太大的意义。 参考：http://wiki.osdev.org/Atomic_operationhttp://www.webopedia.com/TERM/A/atomic_operation.htmlhttp://www.chinaunix.net/jh/23/804826.htmlhttp://odetocode.com/blogs/scott/archive/2006/05/17/atomic-operations.aspx","tags":[{"name":"概念","slug":"概念","permalink":"https://yeqianming.github.io/tags/概念/"},{"name":"C","slug":"C","permalink":"https://yeqianming.github.io/tags/C/"},{"name":"内核","slug":"内核","permalink":"https://yeqianming.github.io/tags/内核/"}]},{"title":"go 连接池实现","path":"2017/02/15/go-连接池实现/","text":"连接池概述连接池可以看做是一个维护了若干连接的一个池子。需要则从其中拿取连接，用完则放回去。 使用连接池可以提升资源的利用率，复用之前使用过的连接，节省创建关闭连接的时间成本，也可以防止出现大量建立连接而对资源的浪费等.也可防止频繁关闭连接出现的 TIME-WAIT 状态的连接。 连接池需要的特性 keeplive ，保持连接 maxCap ，可设置最大连接数 可以释放失效连接 (可选) io超时处理 (可选) 连接超时 one-retry 并发安全 连接池实现 fatih/pool 项目地址Pool 接口123456type Pool interface &#123; //获取连接 Get() (net.Conn, error) Close() Len() int&#125; Pool 实现 channelPool12345678//连接池的实现type channelPool struct &#123; mu sync.Mutex conns chan net.Conn //生成 net.Conn factory Factory&#125; 初始化pool12345678910111213141516171819202122//初始化 Poolfunc NewChannelPool(initialCap, maxCap int, factory Factory) (Pool, error) &#123; if initialCap &lt; 0 || maxCap &lt;= 0 || initialCap &gt; maxCap &#123; return nil, errors.New(&quot;invalid capacity settings&quot;) &#125; c := &amp;channelPool&#123; conns: make(chan net.Conn, maxCap), factory: factory, &#125; //根据参数 初始化池中idle连接 for i := 0; i &lt; initialCap; i++ &#123; conn, err := factory() if err != nil &#123; //有一个连接创建失败，则调用pool的close方法，关闭所有的连接 c.Close() return nil, fmt.Errorf(&quot;factory is not able to fill the pool:%s&quot;, err) &#125; //放入连接池中 c.conns &lt;- conn &#125; return c, nil&#125; 从池中取连接1234567891011121314151617181920212223func (c *channelPool) Get() (net.Conn, error) &#123; conns := c.getConns() if conns == nil &#123; return nil, ErrClosed &#125; select &#123; //从池中获取连接 case conn := &lt;-conns: //连接为nil 则说明 channel Pool 已经关闭 if conn == nil &#123; return nil, ErrClosed &#125; return c.wrapConn(conn), nil default: // pool 中没有空闲的连接，直接申请新的连接 conn, err := c.factory() if err != nil &#123; return nil, err &#125; return c.wrapConn(conn), nil &#125;&#125; 将连接放回池中123456789101112131415161718192021// 关闭连接时，调用放入连接到池中func (c *channelPool) put(conn net.Conn) error &#123; if conn == nil &#123; return errors.New(&quot;connection is nil. rejecting&quot;) &#125; c.mu.Lock() defer c.mu.Unlock() if c.conns == nil &#123; //pool 关闭则直接关闭 return conn.Close() &#125; select &#123; // 放不进去，说明pool 已满 case c.conns &lt;- conn: return nil // 如果pool 已满，那么直接关闭连接 default: return conn.Close() &#125;&#125; 关闭pool1234567891011121314151617func (c *channelPool) Close() &#123; c.mu.Lock() conns := c.conns //快速清空pool c.conns = nil c.factory = nil c.mu.Unlock() if conns == nil &#123; return &#125; close(conns) //一次关闭连接 for conn := range conns &#123; conn.Close() &#125;&#125; 获取 pool1234567//并发安全,比如其他协程正好关闭pool，读取时发生竞争func (c *channelPool) getConns() chan net.Conn &#123; c.mu.Lock() conns := c.conns c.mu.Unlock() return conns&#125; 连接包装 PoolConn123456type PoolConn struct &#123; net.Conn mu sync.RWMutex c *channelPool unusable bool&#125; 包装连接及关闭方法123456// 将pool 和 conn关联起来func (c *channelPool) wrapConn(conn net.Conn) net.Conn &#123; p := &amp;PoolConn&#123;c: c&#125; p.Conn = conn return p&#125; 12345678910111213//重新实现close，关闭连接 优先会尝试放回pool 中func (p *PoolConn) Close() error &#123; p.mu.RLock() defer p.mu.RUnlock() //若连接不可用 则直接调用conn的底层关闭方法 if p.unusable &#123; if p.Conn != nil &#123; return p.Conn.Close() &#125; return nil &#125; return p.c.put(p.Conn)&#125; 标记不可用连接 MarkUnusable12345func (p *PoolConn) MarkUnusable() &#123; p.mu.Lock() p.unusable = true p.mu.Unlock()&#125;","tags":[{"name":"go","slug":"go","permalink":"https://yeqianming.github.io/tags/go/"},{"name":"网络","slug":"网络","permalink":"https://yeqianming.github.io/tags/网络/"}]},{"title":"vim 列编辑模式","path":"2017/02/14/vim-列编辑模式/","text":"删除列 光标定位到要操作的地方。 CTRL+v 进入“可视 块”模式，选取这一列操作多少行。 d 删除。 插入列插入操作的话知识稍有区别。例如我们在每一行前都插入“#”； 光标定位到要插入的地方。 ctrl+v 进入 块模式，选择要操作的块。 shift+i 输入要插入的内容 按 esc 两次","tags":[{"name":"vim","slug":"vim","permalink":"https://yeqianming.github.io/tags/vim/"}]},{"title":"状态和无状态服务器","path":"2017/02/14/状态和无状态服务器/","text":"对于服务器程序来说，有个基本假设，即服务器是基于状态请求，还是基于无状态请求。根据这个假设，可以将服务器划分为状态服务器和无状态服务器。 状态服务器如果是状态化请求，那么服务端一般需要保存请求的相关信息，每个请求可以默认地使用以前的请求信息。 状态服务器具有以下特点：- 保存客户请求的数据（状态）- 服务端容易对客户状态进行管理- 服务端并不要求每次客户请求都携带额外的状态数据 无状态服务器无状态服务器处理的客户信息必须全部来自于请求所携带的信息以及其他服务器自身所保存的、并且可以被所有请求所使用的公共信息。 无状态服务器具有以下特点：- 并不保存客户请求的数据（状态）- 客户在请求时需要携带额外的状态数据- 无状态服务器更加健壮，重启服务器不会丢失状态信息，这使得维护和扩容更加简单 无状态的服务器程序，最著名的就是WEB服务器。每次HTTP请求和以前请求没有直接关联。为了跟踪客户请求的状态信息，请求中加入COOKIE。COOKIE的存在，是无状态化向状态化过渡的一种手段。 参考资料 状态和无状态－－2种服务器架构之间的比较 Stateless vs Stateful Servers","tags":[{"name":"概念","slug":"概念","permalink":"https://yeqianming.github.io/tags/概念/"},{"name":"网络","slug":"网络","permalink":"https://yeqianming.github.io/tags/网络/"},{"name":"web","slug":"web","permalink":"https://yeqianming.github.io/tags/web/"}]},{"title":"聊聊Tcp连接池","path":"2017/02/13/聊聊tcp-连接池/","text":"转载自推酷 概览： 为什么需要连接池 连接失效问题 database/sql 中的连接池 使用连接池管理Thrift链接 以下主要使用Golang作为编程语言 为什么需要连接池我觉得使用连接池最大的一个好处就是 减少连接的创建和关闭，增加系统负载能力 ， 之前就有遇到一个问题： TCP TIME_WAIT连接数过多导致服务不可用 ，因为未开启数据库连接池，再加上mysql并发较大，导致需要频繁的创建链接，最终产生了上万的TIME_WAIT的tcp链接，影响了系统性能。 链接池中的的功能主要是管理一堆的链接，包括创建和关闭，所以自己在 fatih/pool 基础上，改造了一下： https://github.com/silenceper/pool ，使得更加通用一些，增加的一些功能点如下： 连接对象不单单是 net.Conn ,变为了 interface{} （池中存储自己想要的格式） 增加了链接的最大空闲时间（保证了当连接空闲太久，链接失效的问题） 主要是用到了 channel 来管理连接，并且能够很好的利用管道的顺序性，当需要使用的时候 Get 一个连接，使用完毕之后 Put 放回 channel 中。 连接失效问题使用连接池之后就不再是短连接，而是长连接了，就引发了一些问题： 1、长时间空闲，连接断开？因为网络环境是复杂的，中间可能因为防火墙等原因，导致长时间空闲的连接会断开，所以可以通过两个方法来解决： 客户端增加心跳，定时的给服务端发送请求 给连接池中的连接增加最大空闲时间，超时的连接不再使用 在 https://github.com/silenceper/pool 就增加了一个这样最大空闲时间的参数，在连接创建或者连接被重新返回连接池中时重置，给每个连接都增加了一个连接的创建时间，在取出的时候对时间进行比较： https://github.com/silenceper/pool/blob/master/channel.go#L85 2、当服务端重启之后，连接失效？远程服务端很有可能重启，那么之前创建的链接就失效了。客户端在使用的时候就需要判断这些失效的连接并丢弃，在 database/sql 中就判断了这些失效的连接，使用这种错误表示 var ErrBadConn = errors.New(&quot;driver: bad connection&quot;) 另外值得一提的就是在 database/sql 对这种 ErrBadConn 错误进行了重试，默认重试次数是两次，所以能够保证即便是链接失效或者断开了，本次的请求能够正常响应（继续往下看就是分析了）。 连接失效的特征 对连接进行read读操作时，返回 EOF 错误 对连接进行write操作时，返回 write tcp 127.0.0.1:52089-&gt;127.0.0.1:8002: write: broken pipe 错误 database/sql 中的连接池在 database/sql 中使用连接连接池很简单，主要涉及下面这些配置： 123db.SetMaxIdleConns(10) //连接池中最大空闲连接数 db.SetMaxOpenConns(20) //打开的最大连接数 db.SetConnMaxLifetime(300*time.Second)//连接的最大空闲时间(可选) 注：如果 MaxIdleConns 大于0并且 MaxOpenConns 小于 MaxIdleConns ,那么会将 MaxIdleConns 置为 MaxIdleConns 来看下db这个结构，以及字段相关说明： 12345678910111213141516171819202122232425262728293031323334type DB struct &#123; //具体的数据库实现的interface&#123;&#125;, //例如https://github.com/go-sql-driver/mysql 就注册并并实现了driver.Open方法，主要是在里面实现了一些鉴权的操作 driver driver.Driver //dsn连接 dsn string //在prepared statement中用到 numClosed uint64 mu sync.Mutex // protects following fields //可使用的空闲的链接 freeConn []*driverConn //用来传递连接请求的管道 connRequests []chan connRequest //当前打开的连接数 numOpen int //当需要创建新的链接的时候，往这个管道中发送一个struct数据， //因为在Open数据库的就启用了一个goroutine执行connectionOpener方法读取管道中的数据 openerCh chan struct&#123;&#125; //数据库是否已经被关闭 closed bool //用来保证锁被正确的关闭 dep map[finalCloser]depSet //stacktrace of last conn&apos;s put; debug only lastPut map[*driverConn]string //最大空闲连接 maxIdle int //最大打开的连接 maxOpen int //连接的最大空闲时间 maxLifetime time.Duration //定时清理空闲连接的管道 cleanerCh chan struct&#123;&#125;&#125; 看一个查询数据库的例子： 1rows, err := db.Query(&quot;select * from table1&quot;) 在调用 db.Query 方法如下： 123456789101112131415func (db *DB) Query(query string, args ...interface&#123;&#125;) (*Rows, error) &#123; var rows *Rows var err error //这里就做了对失效的链接的重试操作 for i := 0; i &lt; maxBadConnRetries; i++ &#123; rows, err = db.query(query, args, cachedOrNewConn) if err != driver.ErrBadConn &#123; break &#125; &#125; if err == driver.ErrBadConn &#123; return db.query(query, args, alwaysNewConn) &#125; return rows, err&#125; 在什么情况下会返回，可以从这里看到： readPack ， writePack 继续跟进去就到了 1func (db *DB) conn(strategy connReuseStrategy) (*driverConn, error) &#123; 方法主要是创建tcp连接，并判断了连接的生存时间lifetime，以及连接数的一些限制，如果超过的设定的最大打开链接数限制等待 connRequest 管道中有连接产生(在 putConn 释放链接的时候就会往这个管道中写入数据) 何时释放链接?当我们调用 rows.Close() 的时候，就会把当前正在使用的链接重新放回 freeConn 或者写入到 db.connRequests 管道中 123456789101112131415161718192021222324//putConnDBLocked 方法 //如果有db.connRequests有在等待连接的话，就把当前连接给它用 if c := len(db.connRequests); c &gt; 0 &#123; req := db.connRequests[0] // This copy is O(n) but in practice faster than a linked list. // TODO: consider compacting it down less often and // moving the base instead? copy(db.connRequests, db.connRequests[1:]) db.connRequests = db.connRequests[:c-1] if err == nil &#123; dc.inUse = true &#125; req &lt;- connRequest&#123; conn: dc, err: err, &#125; return true &#125; else if err == nil &amp;&amp; !db.closed &amp;&amp; db.maxIdleConnsLocked() &gt; len(db.freeConn) &#123; //没人需要我这个链接，我就把他重新返回`freeConn`连接池中 db.freeConn = append(db.freeConn, dc) db.startCleanerLocked() return true &#125; 使用连接池管理Thrift链接这里是使用连接池 https://github.com/silenceper/pool ，如何构建一个thrift链接 客户端创建Thrift的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455type Client struct &#123; *user.UserClient&#125;//创建Thrift客户端链接的方法factory := func() (interface&#123;&#125;, error) &#123; protocolFactory := thrift.NewTBinaryProtocolFactoryDefault() transportFactory := thrift.NewTTransportFactory() var transport thrift.TTransport var err error transport, err = thrift.NewTSocket(rpcConfig.Listen) if err != nil &#123; panic(err) &#125; transport = transportFactory.GetTransport(transport) //defer transport.Close() if err := transport.Open(); err != nil &#123; panic(err) &#125; rpcClient := user.NewUserClientFactory(transport, protocolFactory) //在连接池中直接放置Client对象 return &amp;Client&#123;UserClient: rpcClient&#125;, nil&#125;//关闭连接的方法close := func(v interface&#123;&#125;) error &#123; v.(*Client).Transport.Close() return nil&#125;//创建了一个 初始化连接是poolConfig := &amp;pool.PoolConfig&#123; InitialCap: 10, MaxCap: 20, Factory: factory, Close: close, IdleTimeout: 300 * time.Second,&#125;p, err := pool.NewChannelPool(poolConfig)if err != nil &#123; panic(err)&#125;//取得链接conn, err := p.Get()if err != nil &#123; return nil, err&#125;v, ok := conn.(*Client)...使用连接调用远程方法//将连接重新放回连接池中p.Put(conn) 写完，听见外面的:rooster:开始打鸣了。","tags":[{"name":"网络","slug":"网络","permalink":"https://yeqianming.github.io/tags/网络/"},{"name":"TCP","slug":"TCP","permalink":"https://yeqianming.github.io/tags/TCP/"}]},{"title":"go位操作","path":"2017/02/13/go位操作/","text":"操作符 AND 按位与 a&amp;b OR 按位或 a 竖杠b XOR 异或 a^b NOT 按位取反 ^a AND NOT 按位清除 a&amp;^b LEFT SHIFT 左移 a&lt;&lt;1 RIGHT SHIFT 右移 a&gt;&gt;1 几种实例 变换符号 123func nagation(a int) int &#123; return ^a + 1&#125; 呼唤变量值 123456func swap(a, b int) (int, int) &#123; a ^= b b ^= a a ^= b return a, b&#125; 求偶数 12345678func even(a int) (array []int) &#123; for i := 0; i &lt; a; i++ &#123; if i&amp;1 == 0 &#123; array = append(array, i) &#125; &#125; return array&#125; 应用bitmap 的实现","tags":[{"name":"go","slug":"go","permalink":"https://yeqianming.github.io/tags/go/"}]},{"title":"下班小聚","path":"2017/02/13/下班小聚/","text":"​ 2017年第一周，星期五，工作任务非常少，轻松愉快 :smile: 。所以果断准备约上几个同事，下班一起聚餐潇洒下。 ​ 在大众点评上找了家评价不错的川菜 –【蜀府】，坐标世博源。发到群里面，小伙伴们纷纷响应报名，大家早早的完成了手头的事，下班准时出发！ 世博源 蜀府 go！ ​ 蜀府这家餐厅位于奔驰中心，门面精致，宾客云集。随便挑了一张大桌落座，边聊边点菜。菜陆陆续续的上来了，细细品尝。这家菜总体上味道不错，尤其是钵钵鸡、水煮鱼、麻婆豆腐等等，味道正宗。但缺点也是有的，譬如上菜很慢，服务员一直劝你多点些菜，茶水收费等等的。 ​ 吃饭期间，气氛很活跃，大家各种八卦、段子，层出不穷，其乐融融。不知不觉，两个小时就过去了，于是买单结账走人。 ​ 路上，看看时间，八点半，大家纷纷嚷着没尽兴，就让凯哥请喝水，找地方坐一坐，结果当凯哥路过一个便利店，转身就要进去买水请客，大家都惊呆了！:scared: 纷纷取笑他抠门， 他招架不住，只好找了家西餐厅，请了档次稍高的酒水。又玩闹了一个小时，大家才各回各家。","tags":[{"name":"生活","slug":"生活","permalink":"https://yeqianming.github.io/tags/生活/"},{"name":"聚餐","slug":"聚餐","permalink":"https://yeqianming.github.io/tags/聚餐/"}]},{"title":"sqlserver 删除依赖","path":"2017/02/10/sqlserver-删除依赖/","text":"遇到的问题 ALTER TABLE DROP COLUMN Areas failed because one or more objects access this column.Msg 5074, Level 16, State 1.The object ‘DFVoucherTyAreas__6748398C’ is dependent on column ‘Areas’. (Line 7) CMD1ALTER TABLE Customer DROP CONSTRAINT Con_First; eg.1alter table vouchertype drop consTRAINT DF__VoucherTy__Areas__6748398C;","tags":[{"name":"数据库","slug":"数据库","permalink":"https://yeqianming.github.io/tags/数据库/"},{"name":"SQLSERVER","slug":"SQLSERVER","permalink":"https://yeqianming.github.io/tags/SQLSERVER/"}]},{"title":"Hello World","path":"2017/02/07/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed enim turpis, sodales ac ullamcorper quis, blandit sed augue. Vivamus eu tortor id elit suscipit convallis. Nam lorem nunc, tristique eget mattis eget, pharetra in est. Pellentesque ac nisi nulla, et vulputate lectus. Ut egestas sodales tortor, vel fringilla mauris ornare quis. Ut nunc nulla, blandit id laoreet facilisis, lobortis eget mauris. Morbi lorem urna, ornare condimentum faucibus at, ullamcorper non turpis. All the world’s a stage, and all the men and women merely players: they have their exits and their entrances; and one man in his time plays many parts… William Shakespeare*As You Like It* Ut dui velit, dapibus vitae scelerisque id, tincidunt vel arcu. Aenean ornare leo in orci pretium eu porttitor nibh venenatis. Curabitur rutrum dolor ac sapien vestibulum interdum in ut felis. Cras ut nisl justo. Suspendisse a lectus enim, vel rutrum urna. Morbi eget sem dui, ac consectetur turpis. Vestibulum ultrices ornare augue at bibendum. Etiam viverra ligula leo. Vestibulum eleifend nulla id leo convallis at bibendum lacus hendrerit. Maecenas placerat feugiat urna, gravida dignissim odio ultrices nec. Maecenas quis adipiscing erat. Phasellus vitae dui a nulla faucibus tincidunt. Nam tempor vestibulum scelerisque. In id libero arcu, nec tincidunt metus. Praesent eu placerat diam. Cras et diam nec augue sagittis mollis. Ut dignissim tempus lectus. Cras pulvinar enim in libero interdum a euismod risus scelerisque. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Vestibulum vel quam vel ante laoreet vestibulum. Nullam porttitor vehicula tellus, sed adipiscing quam eleifend vel. Integer eget ipsum nibh. Ut tellus nisl, ornare ut ultrices vel, ullamcorper eu nisl. Nunc sed nibh mauris, nec dictum justo. He was not of an age, but for all time. Mauris pulvinar purus sit amet felis scelerisque pharetra. Vestibulum tempor est et metus dapibus ut scelerisque augue sollicitudin. Aliquam erat volutpat. Integer quis nunc sapien, non sodales odio. Fusce quis elementum odio. Vestibulum sed porttitor sapien. Aenean accumsan metus sed dolor tincidunt tincidunt. Quisque neque turpis, semper volutpat convallis ut, sagittis ut nibh. Nunc quis erat eget tortor facilisis pretium. Sed non augue in orci consectetur egestas sit amet mattis dolor. Proin blandit, erat sed ultricies eleifend, orci elit condimentum risus, sit amet adipiscing diam augue sit amet massa. Nulla a diam lectus. Aenean nisl tortor, pulvinar in congue at, ullamcorper in metus. Vestibulum eros dolor, tristique ac iaculis sit amet, tempor ut magna. Maecenas venenatis sapien quis lectus tristique bibendum. Donec ultrices tincidunt commodo. Pellentesque euismod tempor felis vitae viverra. Ut luctus nulla vitae dolor placerat sit amet accumsan nulla dictum. Etiam scelerisque accumsan lectus ac ultricies. Donec at urna ut leo rutrum viverra. Ut sed justo orci. Morbi non arcu faucibus nibh eleifend ullamcorper.","tags":[]}]